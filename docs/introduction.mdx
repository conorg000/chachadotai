---
title: Introduction
description: 'AI safety monitoring made simple with behavioral analysis and chain-of-thought monitoring via the SafetyLayer SDK and ChaCha backend platform'
---

<img
  className="block dark:hidden"
  src="/images/hero-light.svg"
  alt="ChaCha Hero Light"
/>
<img
  className="hidden dark:block"
  src="/images/hero-dark.svg"
  alt="ChaCha Hero Dark"
/>

## Welcome to ChaCha

**ChaCha** is a **control plane for AI safety** that provides real-time risk analysis for LLM applications. Unlike traditional content filters, ChaCha operates on two complementary planes to detect subtle security threats through behavioral analysis and chain-of-thought monitoring.

You integrate ChaCha into your application using the **SafetyLayer SDK** â€” a lightweight, open-source client library that sends events to the ChaCha backend for analysis.

<Card title="Why ChaCha?" icon="shield-check" iconType="duotone">
  Traditional AI safety tools focus on input/output filtering. ChaCha goes deeper by analyzing **conversation patterns** and **reasoning processes** to catch threats that bypass simple filters.
</Card>

## Architecture: SafetyLayer SDK + ChaCha Backend

ChaCha uses a modern client-server architecture:

<CardGroup cols={2}>
  <Card title="SafetyLayer SDK" icon="code" iconType="duotone">
    **Lightweight Client Library**
    
    - Simple npm package (`@safetylayer/core`)
    - Record events with one line of code
    - Automatic retry and error handling
    - Type-safe with TypeScript
    - Open source
  </Card>
  
  <Card title="ChaCha Backend" icon="server" iconType="duotone">
    **Centralized Analysis Platform**
    
    - Session-aware behavioral analysis
    - Chain-of-thought monitoring
    - Pattern detection
    - Risk scoring and policy engine
    - Real-time dashboard
  </Card>
</CardGroup>

## The Two-Plane Analysis

ChaCha's backend performs dual-plane monitoring:

<CardGroup cols={2}>
  <Card title="Behavioral Plane" icon="chart-line" iconType="duotone">
    **Session-Aware Risk Analysis**
    
    Tracks risk across multi-turn conversations to detect:
    - Gradual escalation attacks
    - Reconnaissance patterns
    - Social engineering attempts
    - Context-dependent threats
  </Card>
  
  <Card title="CoT Monitoring Plane" icon="brain" iconType="duotone">
    **Reasoning Analysis**
    
    Examines LLM chain-of-thought to detect:
    - Deceptive reasoning
    - Goal drift
    - Policy evasion attempts
    - Hidden intent
  </Card>
</CardGroup>

## Key Features

<AccordionGroup>
  <Accordion title="Simple SDK Integration" icon="plug">
    Install the SafetyLayer SDK and start recording events with minimal code changes. Just a few lines to integrate ChaCha into your app.
  </Accordion>

  <Accordion title="Real-Time Risk Scoring" icon="gauge-high">
    Every event is analyzed and risk scores evolve across conversations with timeline tracking.
  </Accordion>

  <Accordion title="Pattern Detection" icon="magnifying-glass-chart">
    Automatically identify behavioral patterns like `gradual_escalation`, `reconnaissance`, and more.
  </Accordion>

  <Accordion title="Chain-of-Thought Analysis" icon="microscope">
    LLM-powered analysis of model reasoning to detect deception, goal drift, and policy evasion.
  </Accordion>

  <Accordion title="Policy Actions" icon="shield-exclamation">
    Define policies that automatically block, flag, or alert on risky behaviors.
  </Accordion>

  <Accordion title="Session Timeline" icon="clock">
    Full historical view of risk evolution with snapshots at each message.
  </Accordion>

  <Accordion title="TypeScript First" icon="code">
    Built with TypeScript for excellent IDE support and type safety.
  </Accordion>
</AccordionGroup>

## Quick Example

Here's how simple it is to integrate ChaCha using the SafetyLayer SDK:

```typescript
import { SafetyLayer } from '@safetylayer/core';

const safety = new SafetyLayer({
  apiKey: process.env.CHACHA_API_KEY,
  projectId: 'proj_abc123',
  endpoint: 'https://api.chacha.ai', // ChaCha backend
});

// Record user message
await safety.recordUserMessage(sessionId, 'How do I bypass security restrictions?');

// Generate your LLM response
const response = await yourLLM.generate(message);

// Record assistant response
await safety.recordAssistantMessage(sessionId, response.content);

// Record chain-of-thought if available
if (response.reasoning) {
  await safety.recordCoT(sessionId, response.reasoning);
}

// Evaluate risk
const decision = await safety.evaluate({ sessionId });

if (decision.action === 'block') {
  // Session blocked due to safety concerns
  return { error: 'Request blocked' };
}

console.log(`Risk: ${decision.riskScore}`);
console.log(`Patterns: ${decision.patterns.join(', ')}`);
```

## Use Cases

<CardGroup cols={2}>
  <Card title="AI Assistants" icon="robot">
    Monitor customer service bots for manipulation attempts and gradual exploitation
  </Card>
  
  <Card title="Enterprise Chat" icon="building">
    Protect internal LLM tools from prompt injection and data exfiltration
  </Card>
  
  <Card title="Educational AI" icon="graduation-cap">
    Detect students attempting to bypass academic integrity policies
  </Card>
  
  <Card title="Healthcare AI" icon="heart-pulse">
    Ensure medical AI stays within safety guidelines and detects concerning patterns
  </Card>
</CardGroup>

## Architecture Overview

```mermaid
graph TB
    A[Your LLM Application] --> B[SafetyLayer SDK]
    B --> C[ChaCha Backend API]
    
    C --> D[Session Analyzer]
    C --> E[CoT Analyzer]
    C --> F[Policy Engine]
    
    D --> G[Pattern Detection]
    D --> H[Risk Scoring]
    
    E --> I[Deception Detection]
    E --> J[Goal Drift Analysis]
    
    F --> K[Actions: Block/Flag/Alert]
    
    C --> L[(Database)]
    L --> M[Sessions]
    L --> N[Events]
    L --> O[Risk Snapshots]
```

## Get Started

Ready to add SafetyLayer to your application?

<CardGroup cols={2}>
  <Card
    title="Quick Start"
    icon="rocket"
    href="/quickstart"
  >
    Get up and running in 5 minutes
  </Card>
  <Card
    title="Architecture Deep Dive"
    icon="sitemap"
    href="/architecture"
  >
    Understand how SafetyLayer works
  </Card>
  <Card
    title="SDK Reference"
    icon="book"
    href="/api-reference/safetylayer-client"
  >
    Explore the SDK API
  </Card>
  <Card
    title="ChaCha Dashboard"
    icon="chart-line"
    href="/architecture#chacha-dashboard"
  >
    Explore the monitoring dashboard
  </Card>
</CardGroup>

## Open Source

The SafetyLayer SDK is open source and built for the AI safety community. Contributions, feedback, and feature requests are welcome!

<Card
  title="View on GitHub"
  icon="github"
  href="https://github.com/conorg000/chachadotai"
>
  Star us on GitHub and contribute to AI safety
</Card>
