---
title: 'Integration Guide'
description: 'Integrate ChaCha into your application using the SafetyLayer SDK'
---

## Overview

This guide shows how to integrate **ChaCha** AI safety monitoring into different application architectures using the **SafetyLayer SDK**.

<Note>
  Make sure you have your [ChaCha API credentials](/guides/backend-integration) before integrating the SDK.
</Note>

## Express.js Integration

### Basic Setup

```typescript
import express from 'express';
import { SafetyLayer } from '@safetylayer/core';

const app = express();
const safety = new SafetyLayer({
  apiKey: process.env.CHACHA_API_KEY,
  projectId: process.env.CHACHA_PROJECT_ID,
  endpoint: process.env.CHACHA_ENDPOINT || 'https://api.chacha.ai',
});

app.post('/chat', async (req, res) => {
  const { sessionId, message } = req.body;

  try {
    // Record user message
    await safety.recordUserMessage(sessionId, message);

    // Check if session should be blocked
    if (await safety.shouldBlock(sessionId)) {
      return res.status(403).json({ error: 'Session blocked' });
    }

    // Generate LLM response
    const response = await generateLLMResponse(message);

    // Record assistant response
    await safety.recordAssistantMessage(sessionId, response.content);

    // Record CoT if available
    if (response.reasoning) {
      await safety.recordCoT(sessionId, response.reasoning);
    }

    // Get final evaluation
    const decision = await safety.evaluate({ sessionId });

    res.json({
      content: response.content,
      risk: {
        score: decision.riskScore,
        patterns: decision.patterns,
        action: decision.action,
      },
    });
  } catch (error) {
    console.error('Chat error:', error);
    res.status(500).json({ error: 'Internal error' });
  }
});
```

### Middleware Pattern

Create reusable middleware for safety monitoring:

```typescript
import { Request, Response, NextFunction } from 'express';

// Attach ChaCha safety client to request
app.use((req, res, next) => {
  req.safety = safety;
  next();
});

// Pre-check middleware
async function safetyPreCheck(
  req: Request,
  res: Response,
  next: NextFunction
) {
  const sessionId = req.body.sessionId || req.headers['x-session-id'];

  if (await req.safety.shouldBlock(sessionId)) {
    return res.status(403).json({ error: 'Session blocked' });
  }

  next();
}

// Use it
app.post('/chat', safetyPreCheck, async (req, res) => {
  // Process chat...
});
```

## Next.js Integration

### API Route

```typescript
// app/api/chat/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { SafetyLayer } from '@safetylayer/core';

const safety = new SafetyLayer({
  apiKey: process.env.CHACHA_API_KEY!,
  projectId: process.env.CHACHA_PROJECT_ID!,
  endpoint: process.env.CHACHA_ENDPOINT || 'https://api.chacha.ai',
});

export async function POST(req: NextRequest) {
  const { sessionId, message } = await req.json();

  // Record user message
  await safety.recordUserMessage(sessionId, message);

  // Check risk
  const decision = await safety.evaluate({ sessionId });

  if (decision.action === 'block') {
    return NextResponse.json(
      { error: 'Request blocked' },
      { status: 403 }
    );
  }

  // Generate response
  const response = await generateResponse(message);

  // Record assistant message
  await safety.recordAssistantMessage(sessionId, response);

  return NextResponse.json({
    content: response,
    riskScore: decision.riskScore,
  });
}
```

### Server Actions

```typescript
// app/actions.ts
'use server';

import { SafetyLayer } from '@safetylayer/core';

const safety = new SafetyLayer({
  apiKey: process.env.SAFETYLAYER_API_KEY!,
  projectId: process.env.PROJECT_ID!,
});

export async function sendMessage(sessionId: string, message: string) {
  await safety.recordUserMessage(sessionId, message);

  // Check if blocked
  if (await safety.shouldBlock(sessionId)) {
    throw new Error('Session blocked for safety');
  }

  // Process and return response
  const response = await generateResponse(message);
  await safety.recordAssistantMessage(sessionId, response);

  return response;
}
```

## Streaming Responses

Handle streaming LLM responses with SafetyLayer:

```typescript
import { SafetyLayer } from '@safetylayer/core';

async function streamChat(sessionId: string, message: string) {
  const safety = new SafetyLayer({ /* config */ });

  // Record user message
  await safety.recordUserMessage(sessionId, message);

  // Start streaming
  const stream = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: message }],
    stream: true,
  });

  let fullResponse = '';
  
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    fullResponse += content;
    // Stream to client
    yield content;
  }

  // Record complete response
  await safety.recordAssistantMessage(sessionId, fullResponse);

  // Get final evaluation
  const decision = await safety.evaluate({ sessionId });

  yield { risk: decision };
}
```

## Error Handling Patterns

### Graceful Degradation

```typescript
async function handleChat(sessionId: string, message: string) {
  let riskInfo = null;

  try {
    await safety.recordUserMessage(sessionId, message);
    riskInfo = await safety.evaluate({ sessionId });

    if (riskInfo.action === 'block') {
      return { error: 'Blocked', blocked: true };
    }
  } catch (error) {
    // Log but continue if SafetyLayer is down
    console.error('SafetyLayer error:', error);
  }

  // Process message regardless
  const response = await generateResponse(message);

  return { content: response, risk: riskInfo };
}
```

### Fail Closed (Strict)

```typescript
async function handleChat(sessionId: string, message: string) {
  try {
    await safety.recordUserMessage(sessionId, message);
    
    if (await safety.shouldBlock(sessionId)) {
      throw new Error('Session blocked');
    }
  } catch (error) {
    // If SafetyLayer fails, block the request
    console.error('SafetyLayer error:', error);
    throw new Error('Safety check required');
  }

  return await generateResponse(message);
}
```

## Background Processing

Process events asynchronously without blocking responses:

```typescript
import { SafetyLayer } from '@safetylayer/core';

const safety = new SafetyLayer({ /* config */ });

app.post('/chat', async (req, res) => {
  const { sessionId, message } = req.body;

  // Quick pre-check
  const quickCheck = await safety.evaluate({ sessionId });

  if (quickCheck.action === 'block') {
    return res.status(403).json({ error: 'Blocked' });
  }

  // Generate response
  const response = await generateResponse(message);

  // Send response immediately
  res.json({ content: response });

  // Record events in background (don't await)
  safety.recordUserMessage(sessionId, message).catch(console.error);
  safety.recordAssistantMessage(sessionId, response).catch(console.error);
  
  // Background evaluation
  safety.evaluate({ sessionId }).then((decision) => {
    if (decision.action === 'block') {
      // Take async action (e.g., send webhook, alert)
      notifySecurityTeam(sessionId, decision);
    }
  });
});
```

## Session ID Strategies

### User-Based Sessions

```typescript
// One session per user
const sessionId = `user_${userId}`;
```

### Conversation-Based Sessions

```typescript
// New session for each conversation
const sessionId = SafetyLayer.generateSessionId();
// Store in database with conversationId
```

### Time-Based Sessions

```typescript
// Reset session daily
const today = new Date().toISOString().split('T')[0];
const sessionId = `user_${userId}_${today}`;
```

## Best Practices

<AccordionGroup>
  <Accordion title="Always Handle Errors" icon="shield-check">
    Never let SafetyLayer errors crash your app. Use try-catch and decide whether to fail open or closed.
  </Accordion>

  <Accordion title="Record Events Promptly" icon="clock">
    Record user messages before processing and assistant messages after generation.
  </Accordion>

  <Accordion title="Evaluate at Key Points" icon="checkpoint">
    Evaluate before expensive operations (LLM calls) and after critical responses.
  </Accordion>

  <Accordion title="Use Consistent Session IDs" icon="fingerprint">
    Choose a session ID strategy and stick to it across your application.
  </Accordion>

  <Accordion title="Monitor SDK Performance" icon="gauge">
    Track latency and error rates to ensure SafetyLayer doesn't slow down your app.
  </Accordion>
</AccordionGroup>

## Related

<CardGroup cols={2}>
  <Card
    title="SDK API Reference"
    icon="code"
    href="/api-reference/safetylayer-client"
  >
    Complete SDK documentation
  </Card>
  
  <Card
    title="Backend Setup"
    icon="server"
    href="/guides/backend-integration"
  >
    Set up the backend
  </Card>
  
  <Card
    title="Error Handling"
    icon="triangle-exclamation"
    href="/api-reference/error-handling"
  >
    Error handling patterns
  </Card>
  
  <Card
    title="Testing"
    icon="flask"
    href="/guides/testing"
  >
    Testing your integration
  </Card>
</CardGroup>
